{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from data_processing import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from data_transformar import *\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import PCA\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "cheat = pd.read_csv(\"./result-with-best.csv\")\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cheat_score(model):\n",
    "    print(\"RMSLE sub: \" + str(rmsle(model.predict(validation), np.log1p(cheat[\"SalePrice\"]))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./train.csv\")\n",
    "data = data.drop(columns=[\"Id\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([249, 313, 335, 523, 706, 1298], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "data = remove_outliers(data, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1454, 79)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0          60       RL         65.0     8450   Pave   NaN      Reg   \n1          20       RL         80.0     9600   Pave   NaN      Reg   \n2          60       RL         68.0    11250   Pave   NaN      IR1   \n3          70       RL         60.0     9550   Pave   NaN      IR1   \n4          60       RL         84.0    14260   Pave   NaN      IR1   \n\n  LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC Fence  \\\n0         Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n1         Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n2         Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n3         Lvl    AllPub    Corner  ...           0        0    NaN   NaN   \n4         Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n\n  MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n0         NaN       0       2    2008        WD         Normal  \n1         NaN       0       5    2007        WD         Normal  \n2         NaN       0       9    2008        WD         Normal  \n3         NaN       0       2    2006        WD        Abnorml  \n4         NaN       0      12    2008        WD         Normal  \n\n[5 rows x 79 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>LotConfig</th>\n      <th>...</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>FR2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Corner</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>FR2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 79 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.log1p(data[\"SalePrice\"])\n",
    "X = data.drop(columns=[\"SalePrice\"])\n",
    "\n",
    "print(X.shape)\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=98987)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1163, 34) (1163, 275)\n",
      "(291, 34) (291, 275)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig = X_train.copy()\n",
    "\n",
    "transformer = DataTransformer(StandardScaler())\n",
    "\n",
    "X_train = transformer.prepare(X_train)\n",
    "X_test = transformer.prepare(X_test)\n",
    "\n",
    "transformer.fit(X_train)\n",
    "\n",
    "X_train = transformer.transform(X_train)\n",
    "X_test = transformer.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": "   LotFrontage  LotArea  YearBuilt  MasVnrArea  BsmtFinSF1  BsmtFinSF2  \\\n0    50.000000   6000.0     1926.0         0.0         0.0         0.0   \n1    79.000000  12420.0     2001.0         0.0       666.0         0.0   \n2   100.000000  10004.0     1964.0       180.0       196.0       345.0   \n3    61.524801   3950.0     1926.0         0.0       468.0         0.0   \n4    60.000000   8172.0     1954.0         0.0         0.0         0.0   \n\n   BsmtUnfSF  TotalBsmtSF  1stFlrSF  2ndFlrSF  ...  309  310  311  312  313  \\\n0      884.0        884.0     904.0       0.0  ...  0.0  0.0  0.0  1.0  0.0   \n1      278.0        944.0     944.0     896.0  ...  0.0  0.0  0.0  1.0  0.0   \n2      975.0       1516.0    1516.0       0.0  ...  0.0  0.0  0.0  1.0  0.0   \n3      350.0        818.0     818.0     406.0  ...  0.0  0.0  0.0  1.0  0.0   \n4      941.0        941.0     997.0     473.0  ...  0.0  0.0  0.0  1.0  0.0   \n\n   314  315  316  317  318  \n0  0.0  0.0  0.0  1.0  0.0  \n1  0.0  0.0  0.0  1.0  0.0  \n2  0.0  0.0  0.0  1.0  0.0  \n3  0.0  0.0  0.0  1.0  0.0  \n4  0.0  0.0  0.0  1.0  0.0  \n\n[5 rows x 347 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>YearBuilt</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>BsmtUnfSF</th>\n      <th>TotalBsmtSF</th>\n      <th>1stFlrSF</th>\n      <th>2ndFlrSF</th>\n      <th>...</th>\n      <th>309</th>\n      <th>310</th>\n      <th>311</th>\n      <th>312</th>\n      <th>313</th>\n      <th>314</th>\n      <th>315</th>\n      <th>316</th>\n      <th>317</th>\n      <th>318</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50.000000</td>\n      <td>6000.0</td>\n      <td>1926.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>884.0</td>\n      <td>884.0</td>\n      <td>904.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>79.000000</td>\n      <td>12420.0</td>\n      <td>2001.0</td>\n      <td>0.0</td>\n      <td>666.0</td>\n      <td>0.0</td>\n      <td>278.0</td>\n      <td>944.0</td>\n      <td>944.0</td>\n      <td>896.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100.000000</td>\n      <td>10004.0</td>\n      <td>1964.0</td>\n      <td>180.0</td>\n      <td>196.0</td>\n      <td>345.0</td>\n      <td>975.0</td>\n      <td>1516.0</td>\n      <td>1516.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61.524801</td>\n      <td>3950.0</td>\n      <td>1926.0</td>\n      <td>0.0</td>\n      <td>468.0</td>\n      <td>0.0</td>\n      <td>350.0</td>\n      <td>818.0</td>\n      <td>818.0</td>\n      <td>406.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60.000000</td>\n      <td>8172.0</td>\n      <td>1954.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>941.0</td>\n      <td>941.0</td>\n      <td>997.0</td>\n      <td>473.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 347 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.isnull().sum().sum())\n",
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 34) (1459, 275)\n"
     ]
    }
   ],
   "source": [
    "#cheat sheet\n",
    "validation = pd.read_csv(\"./test.csv\")\n",
    "val_ids = validation[\"Id\"]\n",
    "validation = validation.drop(columns=[\"Id\"])\n",
    "validation_orig = validation.copy()\n",
    "validation = transformer.prepare(validation)\n",
    "\n",
    "validation = transformer.transform(validation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def evaluate(model, X, y):\n",
    "    preds = model.predict(X)\n",
    "    print(\"RMSLE: \" + str(rmsle(preds, y)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Гоняем котов"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cat_features = np.where(X_train.loc[:, X_train.columns.values].dtypes == \"object\")[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostRegressor at 0x186abeaeac8>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "dev_pool = Pool(X_test, y_test, cat_features=cat_features)\n",
    "\n",
    "cat_model = CatBoostRegressor(task_type=\"GPU\",  devices='0:1')\n",
    "cat_model.fit(train_pool, eval_set=dev_pool, early_stopping_rounds=10, verbose=0, plot=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.08480163619676472\n",
      "RMSLE: 0.12142366767537342\n"
     ]
    }
   ],
   "source": [
    "evaluate(cat_model, X_train, y_train)\n",
    "evaluate(cat_model, X_test, y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Конвертим данные под lgb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "outputs": [],
   "source": [
    "def to_categorical(X):\n",
    "    for c in X.columns:\n",
    "        col_type = X[c].dtype\n",
    "        if col_type == 'object' or col_type.name == 'category':\n",
    "            X[c] = X[c].astype('category')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "outputs": [],
   "source": [
    "#to_categorical(X_train)\n",
    "#to_categorical(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "data": {
      "text/plain": "LGBMRegressor(bagging_fraction=0.75, bagging_freq=5, bagging_seed=7,\n              feature_fraction=0.2, feature_fraction_seed=7, learning_rate=0.01,\n              max_bin=200, n_estimators=5000, num_leaves=4, verbose=-1)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "clf = lgb.LGBMRegressor(\n",
    "                        num_leaves=4,\n",
    "                        learning_rate=0.01,\n",
    "                        n_estimators=5000,\n",
    "                        max_bin=200,\n",
    "                        bagging_fraction=0.75,\n",
    "                        bagging_freq=5,\n",
    "                        bagging_seed=7,\n",
    "                        feature_fraction=0.2,\n",
    "                        feature_fraction_seed=7,\n",
    "                        verbose=-1,)\n",
    "\n",
    "fit_params = {\"early_stopping_rounds\": 20,\n",
    "              \"eval_metric\": 'rmse',\n",
    "              \"eval_set\": [(X_test, y_test)],\n",
    "              'verbose': -1,\n",
    "              #'categorical_feature': cat_features\n",
    "              }\n",
    "clf.fit(X_train, y_train, **fit_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.10045462575549441\n",
      "RMSLE: 0.1238929594778791\n"
     ]
    }
   ],
   "source": [
    "evaluate(clf, X_train, y_train)\n",
    "evaluate(clf, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from hyperopt import fmin, tpe, hp, anneal, Trials\n",
    "\n",
    "folds = 4\n",
    "shuffle = True\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "def objective(params):\n",
    "    params = {'n_estimators': int(params['n_estimators']),\n",
    "              'max_depth': int(params['max_depth']),\n",
    "              'learning_rate': params['learning_rate'],\n",
    "              'num_leaves': int(params['num_leaves'])}\n",
    "\n",
    "    clf = lgb.LGBMRegressor(random_state=random_state, **params)\n",
    "\n",
    "    kf = KFold(n_splits=folds, shuffle=shuffle)\n",
    "    loss_list = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        clf_fold = clone(clf)\n",
    "        clf_fold.fit(X_train_fold, y_train_fold, **fit_params)\n",
    "\n",
    "        prediction = clf_fold.predict(X_test_fold)\n",
    "        loss = rmsle(prediction, y_test_fold)\n",
    "        loss_list.append(loss)\n",
    "\n",
    "    score = np.mean(loss_list)\n",
    "\n",
    "    #print(\"{:.3f} params {}\".format(score, params))\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:44<00:00,  1.04s/trial, best loss: 0.13087101505524557]\n",
      "best {'learning_rate': 0.015258745896343552, 'max_depth': 13.0, 'n_estimators': 1470.0, 'num_leaves': 4.0}\n"
     ]
    }
   ],
   "source": [
    "space={'n_estimators': hp.quniform('n_estimators', 100, 10000, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 2, 30, 1),\n",
    "       'num_leaves' : hp.quniform('num_leaves', 2, 40, 1),\n",
    "       'learning_rate': hp.loguniform('learning_rate', -5, 0)\n",
    "       }\n",
    "trials = Trials()\n",
    "\n",
    "best=fmin(fn=objective, # function to optimize\n",
    "          space=space,\n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          trials=trials, # logging\n",
    "          rstate = np.random.default_rng(random_state) # fixing random state for the reproducibility\n",
    "          )\n",
    "\n",
    "print(\"best {}\".format(best))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.09229238390761943\n",
      "RMSLE: 0.12273039662705652\n"
     ]
    }
   ],
   "source": [
    "lbg_model = lgb.LGBMRegressor(random_state=random_state, n_estimators=int(best['n_estimators']),\n",
    "                      max_depth=int(best['max_depth']), learning_rate=best['learning_rate'], num_leaves = int(best['num_leaves']))\n",
    "lbg_model.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "evaluate(lbg_model, X_train, y_train)\n",
    "evaluate(lbg_model, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.00429847343939635\n",
      "RMSLE: 0.11218768778696825\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(\n",
    "    colsample_bytree=1.,\n",
    "    eta=0.01,\n",
    "    max_depth=4,\n",
    "    min_child_weight=1.5,\n",
    "    n_estimators=14400,\n",
    "    alpha=0.,\n",
    "    reg_lambda=0.4,\n",
    "    subsample=0.2)\n",
    "\n",
    "xgb_model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "evaluate(xgb_model, X_train, y_train)\n",
    "evaluate(xgb_model, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE sub: 0.13712472408972484\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSLE sub: \" + str(rmsle(xgb_model.predict(validation), np.log1p(cheat[\"SalePrice\"]))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 347 and input n_features is 309",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_48836/2774813645.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;36m3\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mlbg_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;36m3\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mcat_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;36m3\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mxgb_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpredict_blend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"RMSLE: \"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrmsle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_48836/2774813645.py\u001B[0m in \u001B[0;36mpredict_blend\u001B[1;34m(X)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mpredict_blend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;36m3\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mlbg_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;36m3\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mcat_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;36m3\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mxgb_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpredict_blend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"RMSLE: \"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrmsle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\lightgbm\\sklearn.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001B[0m\n\u001B[0;32m    798\u001B[0m         \u001B[0mn_features\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    799\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_features\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mn_features\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 800\u001B[1;33m             raise ValueError(\"Number of features of the model must \"\n\u001B[0m\u001B[0;32m    801\u001B[0m                              \u001B[1;34mf\"match the input. Model n_features_ is {self._n_features} and \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    802\u001B[0m                              f\"input n_features is {n_features}\")\n",
      "\u001B[1;31mValueError\u001B[0m: Number of features of the model must match the input. Model n_features_ is 347 and input n_features is 309"
     ]
    }
   ],
   "source": [
    "def predict_blend(X):\n",
    "    return 1/3 * lbg_model.predict(X) + 1/3 * cat_model.predict(X) + 1/3 * xgb_model.predict(X)\n",
    "\n",
    "predictions = predict_blend(X_train)\n",
    "print(\"RMSLE: \" + str(rmsle(predictions, y_train)))\n",
    "\n",
    "predictions = predict_blend(X_test)\n",
    "print(\"RMSLE: \" + str(rmsle(predictions, y_test)))\n",
    "\n",
    "print(\"RMSLE sub: \" + str(rmsle(predict_blend(validation), np.log1p(cheat[\"SalePrice\"]))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### где мы косячим"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 347 and input n_features is 309",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_48836/1108730520.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdifferences\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mabs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexpm1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredict_blend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalidation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mcheat\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"SalePrice\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0moutliers_ids\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdifferences\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m200000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdifferences\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_48836/2774813645.py\u001B[0m in \u001B[0;36mpredict_blend\u001B[1;34m(X)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mpredict_blend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;36m3\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mlbg_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;36m3\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mcat_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;36m3\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mxgb_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpredict_blend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"RMSLE: \"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrmsle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\lightgbm\\sklearn.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001B[0m\n\u001B[0;32m    798\u001B[0m         \u001B[0mn_features\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    799\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_features\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mn_features\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 800\u001B[1;33m             raise ValueError(\"Number of features of the model must \"\n\u001B[0m\u001B[0;32m    801\u001B[0m                              \u001B[1;34mf\"match the input. Model n_features_ is {self._n_features} and \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    802\u001B[0m                              f\"input n_features is {n_features}\")\n",
      "\u001B[1;31mValueError\u001B[0m: Number of features of the model must match the input. Model n_features_ is 347 and input n_features is 309"
     ]
    }
   ],
   "source": [
    "differences = np.abs((np.expm1(predict_blend(validation)) - cheat[\"SalePrice\"]))\n",
    "\n",
    "outliers_ids = np.where(differences > 200000)[0]\n",
    "plt.plot(differences.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "   MSSubClass  LotFrontage      LotArea  OverallQual  OverallCond  \\\n0   57.378341    68.580357  9819.161069     6.078821     5.553804   \n\n     YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  \\\n0  1971.357779   1983.662783  100.709141  439.203704   52.619342  ...   \n\n   GarageArea  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\n0  472.768861   93.174777    48.313914      24.243317    1.79438    17.064428   \n\n   PoolArea    MiscVal    MoSold       YrSold  \n0  1.744345  58.167923  6.104181  2007.769705  \n\n[1 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57.378341</td>\n      <td>68.580357</td>\n      <td>9819.161069</td>\n      <td>6.078821</td>\n      <td>5.553804</td>\n      <td>1971.357779</td>\n      <td>1983.662783</td>\n      <td>100.709141</td>\n      <td>439.203704</td>\n      <td>52.619342</td>\n      <td>...</td>\n      <td>472.768861</td>\n      <td>93.174777</td>\n      <td>48.313914</td>\n      <td>24.243317</td>\n      <td>1.79438</td>\n      <td>17.064428</td>\n      <td>1.744345</td>\n      <td>58.167923</td>\n      <td>6.104181</td>\n      <td>2007.769705</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_candidates = list(validation_orig.dtypes[validation_orig.dtypes != \"object\"].index.values)\n",
    "\n",
    "outliers_data = validation_orig.iloc[outliers_ids][num_candidates]\n",
    "df = pd.DataFrame(data=validation_orig[num_candidates].mean())\n",
    "#df.T.head()\n",
    "df.T\n",
    "#sns.displot(outliers_data['LotFrontage'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n33            60         85.0    13143            8            5       1993   \n53            90         98.0    13260            5            6       1962   \n76            30         68.0     9656            2            2       1923   \n78            70         50.0     9000            8            9       1890   \n112           20         44.0    17485            7            5       2009   \n203           20        105.0    13693           10            5       2007   \n204           20         95.0    11578            9            5       2008   \n217           20        100.0    14836           10            5       2004   \n454          120         44.0     3843            8            5       2007   \n509           60        108.0    13418            9            5       2006   \n514           20        106.0    12720           10            5       2003   \n570          120          NaN     4538            9            5       2001   \n572          120         35.0     4109            9            5       1999   \n577          160         36.0     3951           10            5       1998   \n579           60          NaN    24572            9            3       1977   \n691           30         85.0    19550            5            7       1940   \n701           20         91.0    11778            9            5       2008   \n756           20         80.0    14584            1            5       1952   \n803           20         52.0    51974            9            5       2006   \n964           70        113.0    21281            5            4       1935   \n1032          20          NaN    17541            5            7       1948   \n1046          20         93.0    10481            8            5       2006   \n1089          20        128.0    39290           10            5       2008   \n1122         120         59.0     5568            8            5       2006   \n1222          60        114.0    17242            9            5       1993   \n1251          60        105.0    11025            8            5       1992   \n1362          75         60.0    19800            6            8       1935   \n\n      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n33            1993       504.0       250.0       981.0  ...       762.0   \n53            2001       144.0      1500.0         0.0  ...         0.0   \n76            1970         0.0         0.0         0.0  ...       780.0   \n78            2002         0.0         0.0         0.0  ...       624.0   \n112           2010        96.0      1346.0         0.0  ...       572.0   \n203           2007       472.0      2288.0         0.0  ...       762.0   \n204           2008       302.0         0.0         0.0  ...       834.0   \n217           2005       730.0      2146.0         0.0  ...       949.0   \n454           2008       174.0      1476.0         0.0  ...       482.0   \n509           2006       270.0      1420.0         0.0  ...       850.0   \n514           2003       680.0      2257.0         0.0  ...       789.0   \n570           2001       179.0      1004.0         0.0  ...       545.0   \n572           2000       260.0      1141.0         0.0  ...       484.0   \n577           1999         0.0       128.0       842.0  ...       846.0   \n579           1977      1050.0       410.0         0.0  ...       864.0   \n691           2007         0.0      1035.0         0.0  ...         0.0   \n701           2008       554.0      2085.0         0.0  ...      1348.0   \n756           1952         0.0         0.0         0.0  ...       487.0   \n803           2007       710.0      1101.0         0.0  ...      1110.0   \n964           2007         0.0         0.0         0.0  ...      1200.0   \n1032          2005         0.0       300.0         0.0  ...       576.0   \n1046          2007         0.0         0.0         0.0  ...       894.0   \n1089          2009      1224.0      4010.0         0.0  ...      1154.0   \n1122          2007       473.0      1573.0         0.0  ...       495.0   \n1222          1994       738.0       292.0      1393.0  ...       959.0   \n1251          1993       692.0      1118.0         0.0  ...       888.0   \n1362          1990         0.0       425.0         0.0  ...       836.0   \n\n      WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\n33            32          130              0          0            0   \n53             0            0              0          0            0   \n76             0            0              0          0            0   \n78             0          108              0          0            0   \n112            0            0              0          0            0   \n203          360           50              0          0            0   \n204          319           90              0          0            0   \n217          226          235              0          0            0   \n454          162           53              0        153            0   \n509          212          182              0          0            0   \n514          154           65              0          0          216   \n570          277           45              0          0            0   \n572          124          113              0          0            0   \n577            0           90              0          0           94   \n579          140           70             16          0            0   \n691            0           39              0          0            0   \n701            0            0             70          0          255   \n756            0            0              0          0            0   \n803            0          135              0          0          322   \n964            0          208            290          0          156   \n1032           0           42              0          0            0   \n1046         136           32              0          0            0   \n1089         546          484              0          0            0   \n1122         123            0              0          0          153   \n1222         870           86              0          0          210   \n1251         177          208            186          0            0   \n1362         684           80             32          0            0   \n\n      PoolArea  MiscVal  MoSold  YrSold  \n33           0        0       6    2010  \n53           0        0       1    2010  \n76           0        0       6    2010  \n78           0        0       4    2010  \n112          0        0       1    2010  \n203          0        0       3    2009  \n204          0        0       7    2009  \n217          0        0       2    2009  \n454          0        0       6    2009  \n509          0        0      10    2008  \n514        144        0       2    2008  \n570          0        0       7    2008  \n572          0        0       6    2008  \n577          0        0       2    2008  \n579          0        0       6    2008  \n691          0        0       1    2008  \n701          0        0       6    2008  \n756          0        0       2    2008  \n803          0        0       6    2007  \n964          0        0      11    2007  \n1032         0        0       7    2007  \n1046         0        0       6    2007  \n1089         0    17000      10    2007  \n1122         0        0      10    2007  \n1222         0        0       5    2006  \n1251         0        0      10    2006  \n1362         0        0      12    2006  \n\n[27 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33</th>\n      <td>60</td>\n      <td>85.0</td>\n      <td>13143</td>\n      <td>8</td>\n      <td>5</td>\n      <td>1993</td>\n      <td>1993</td>\n      <td>504.0</td>\n      <td>250.0</td>\n      <td>981.0</td>\n      <td>...</td>\n      <td>762.0</td>\n      <td>32</td>\n      <td>130</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>90</td>\n      <td>98.0</td>\n      <td>13260</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1962</td>\n      <td>2001</td>\n      <td>144.0</td>\n      <td>1500.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>30</td>\n      <td>68.0</td>\n      <td>9656</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1923</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>780.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>70</td>\n      <td>50.0</td>\n      <td>9000</td>\n      <td>8</td>\n      <td>9</td>\n      <td>1890</td>\n      <td>2002</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>624.0</td>\n      <td>0</td>\n      <td>108</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>20</td>\n      <td>44.0</td>\n      <td>17485</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2009</td>\n      <td>2010</td>\n      <td>96.0</td>\n      <td>1346.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>572.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>20</td>\n      <td>105.0</td>\n      <td>13693</td>\n      <td>10</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>2007</td>\n      <td>472.0</td>\n      <td>2288.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>762.0</td>\n      <td>360</td>\n      <td>50</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>204</th>\n      <td>20</td>\n      <td>95.0</td>\n      <td>11578</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2008</td>\n      <td>2008</td>\n      <td>302.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>834.0</td>\n      <td>319</td>\n      <td>90</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>20</td>\n      <td>100.0</td>\n      <td>14836</td>\n      <td>10</td>\n      <td>5</td>\n      <td>2004</td>\n      <td>2005</td>\n      <td>730.0</td>\n      <td>2146.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>949.0</td>\n      <td>226</td>\n      <td>235</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>454</th>\n      <td>120</td>\n      <td>44.0</td>\n      <td>3843</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>2008</td>\n      <td>174.0</td>\n      <td>1476.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>482.0</td>\n      <td>162</td>\n      <td>53</td>\n      <td>0</td>\n      <td>153</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>60</td>\n      <td>108.0</td>\n      <td>13418</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2006</td>\n      <td>2006</td>\n      <td>270.0</td>\n      <td>1420.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>850.0</td>\n      <td>212</td>\n      <td>182</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>514</th>\n      <td>20</td>\n      <td>106.0</td>\n      <td>12720</td>\n      <td>10</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>680.0</td>\n      <td>2257.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>789.0</td>\n      <td>154</td>\n      <td>65</td>\n      <td>0</td>\n      <td>0</td>\n      <td>216</td>\n      <td>144</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>570</th>\n      <td>120</td>\n      <td>NaN</td>\n      <td>4538</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2001</td>\n      <td>179.0</td>\n      <td>1004.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>545.0</td>\n      <td>277</td>\n      <td>45</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>572</th>\n      <td>120</td>\n      <td>35.0</td>\n      <td>4109</td>\n      <td>9</td>\n      <td>5</td>\n      <td>1999</td>\n      <td>2000</td>\n      <td>260.0</td>\n      <td>1141.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>484.0</td>\n      <td>124</td>\n      <td>113</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>577</th>\n      <td>160</td>\n      <td>36.0</td>\n      <td>3951</td>\n      <td>10</td>\n      <td>5</td>\n      <td>1998</td>\n      <td>1999</td>\n      <td>0.0</td>\n      <td>128.0</td>\n      <td>842.0</td>\n      <td>...</td>\n      <td>846.0</td>\n      <td>0</td>\n      <td>90</td>\n      <td>0</td>\n      <td>0</td>\n      <td>94</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>579</th>\n      <td>60</td>\n      <td>NaN</td>\n      <td>24572</td>\n      <td>9</td>\n      <td>3</td>\n      <td>1977</td>\n      <td>1977</td>\n      <td>1050.0</td>\n      <td>410.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>864.0</td>\n      <td>140</td>\n      <td>70</td>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>691</th>\n      <td>30</td>\n      <td>85.0</td>\n      <td>19550</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1940</td>\n      <td>2007</td>\n      <td>0.0</td>\n      <td>1035.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>39</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>701</th>\n      <td>20</td>\n      <td>91.0</td>\n      <td>11778</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2008</td>\n      <td>2008</td>\n      <td>554.0</td>\n      <td>2085.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1348.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>70</td>\n      <td>0</td>\n      <td>255</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>756</th>\n      <td>20</td>\n      <td>80.0</td>\n      <td>14584</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1952</td>\n      <td>1952</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>487.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>803</th>\n      <td>20</td>\n      <td>52.0</td>\n      <td>51974</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2006</td>\n      <td>2007</td>\n      <td>710.0</td>\n      <td>1101.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1110.0</td>\n      <td>0</td>\n      <td>135</td>\n      <td>0</td>\n      <td>0</td>\n      <td>322</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>964</th>\n      <td>70</td>\n      <td>113.0</td>\n      <td>21281</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1935</td>\n      <td>2007</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1200.0</td>\n      <td>0</td>\n      <td>208</td>\n      <td>290</td>\n      <td>0</td>\n      <td>156</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>1032</th>\n      <td>20</td>\n      <td>NaN</td>\n      <td>17541</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1948</td>\n      <td>2005</td>\n      <td>0.0</td>\n      <td>300.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>576.0</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>1046</th>\n      <td>20</td>\n      <td>93.0</td>\n      <td>10481</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2006</td>\n      <td>2007</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>894.0</td>\n      <td>136</td>\n      <td>32</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>1089</th>\n      <td>20</td>\n      <td>128.0</td>\n      <td>39290</td>\n      <td>10</td>\n      <td>5</td>\n      <td>2008</td>\n      <td>2009</td>\n      <td>1224.0</td>\n      <td>4010.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1154.0</td>\n      <td>546</td>\n      <td>484</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17000</td>\n      <td>10</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>1122</th>\n      <td>120</td>\n      <td>59.0</td>\n      <td>5568</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2006</td>\n      <td>2007</td>\n      <td>473.0</td>\n      <td>1573.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>495.0</td>\n      <td>123</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>153</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>1222</th>\n      <td>60</td>\n      <td>114.0</td>\n      <td>17242</td>\n      <td>9</td>\n      <td>5</td>\n      <td>1993</td>\n      <td>1994</td>\n      <td>738.0</td>\n      <td>292.0</td>\n      <td>1393.0</td>\n      <td>...</td>\n      <td>959.0</td>\n      <td>870</td>\n      <td>86</td>\n      <td>0</td>\n      <td>0</td>\n      <td>210</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>1251</th>\n      <td>60</td>\n      <td>105.0</td>\n      <td>11025</td>\n      <td>8</td>\n      <td>5</td>\n      <td>1992</td>\n      <td>1993</td>\n      <td>692.0</td>\n      <td>1118.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>888.0</td>\n      <td>177</td>\n      <td>208</td>\n      <td>186</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>1362</th>\n      <td>75</td>\n      <td>60.0</td>\n      <td>19800</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1935</td>\n      <td>1990</td>\n      <td>0.0</td>\n      <td>425.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>836.0</td>\n      <td>684</td>\n      <td>80</td>\n      <td>32</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2006</td>\n    </tr>\n  </tbody>\n</table>\n<p>27 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Full dataset & submit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 23) (1460, 342)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./train.csv\")\n",
    "data = data.drop(columns=[\"Id\"])\n",
    "\n",
    "#data = remove_outliers(data)\n",
    "\n",
    "y = np.log1p(data[\"SalePrice\"])\n",
    "X = data.drop(columns=[\"SalePrice\"])\n",
    "\n",
    "transformer = DataTransformer(StandardScaler())\n",
    "X = transformer.prepare(X)\n",
    "\n",
    "transformer.fit(X)\n",
    "\n",
    "X = transformer.transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 23) (1459, 342)\n"
     ]
    }
   ],
   "source": [
    "validation = pd.read_csv(\"./test.csv\")\n",
    "val_ids = validation[\"Id\"]\n",
    "validation = validation.drop(columns=[\"Id\"])\n",
    "\n",
    "validation = transformer.prepare(validation)\n",
    "\n",
    "validation = transformer.transform(validation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "outputs": [],
   "source": [
    "#to_categorical(X)\n",
    "#to_categorical(validation)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 9.76679802624231e-05\n",
      "RMSLE sub: 0.1349601751806444\n"
     ]
    }
   ],
   "source": [
    "fit_params = {\n",
    "              \"eval_metric\": 'rmse',\n",
    "              'verbose': -1,\n",
    "              #'categorical_feature': cat_features\n",
    "              }\n",
    "lbg_model = lgb.LGBMRegressor(random_state=random_state, n_estimators=int(best['n_estimators']),\n",
    "                              max_depth=int(best['max_depth']), learning_rate=best['learning_rate'], num_leaves = int(best['num_leaves']))\n",
    "lbg_model.fit(X, y, **fit_params)\n",
    "\n",
    "predictions = lbg_model.predict(X)\n",
    "print(\"RMSLE: \" + str(rmsle(predictions, y)))\n",
    "\n",
    "cheat_score(lbg_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.06669332604267621\n",
      "RMSLE sub: 0.13496761506078175\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cat_features = np.where(X.loc[:, X.columns.values].dtypes == \"object\")[0]\n",
    "train_pool = Pool(X, y, cat_features=cat_features)\n",
    "\n",
    "cat_model = CatBoostRegressor(iterations=10000, task_type=\"GPU\", devices='0:1')\n",
    "cat_model.fit(train_pool, verbose=0, plot=False)\n",
    "\n",
    "predictions = cat_model.predict(X)\n",
    "print(\"RMSLE: \" + str(rmsle(predictions, y)))\n",
    "\n",
    "cheat_score(cat_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.00792294912043575\n",
      "RMSLE sub: 0.13603994105209535\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(\n",
    "    colsample_bytree=1.,\n",
    "    eta=0.01,\n",
    "    max_depth=4,\n",
    "    min_child_weight=1.5,\n",
    "    n_estimators=14400,\n",
    "    alpha=0.,\n",
    "    reg_lambda=0.4,\n",
    "    subsample=0.2)\n",
    "\n",
    "xgb_model.fit(X, y, verbose=False)\n",
    "\n",
    "predictions = xgb_model.predict(X)\n",
    "print(\"RMSLE: \" + str(rmsle(predictions, y)))\n",
    "cheat_score(xgb_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "outputs": [],
   "source": [
    "def predict_blend(X):\n",
    "    return 0.1 * lbg_model.predict(X) + 0.1 * cat_model.predict(X) + 0.8 * xgb_model.predict(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.011633915778626484\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_blend(X)\n",
    "print(\"RMSLE: \" + str(rmsle(predictions, y)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "outputs": [
    {
     "data": {
      "text/plain": "<seaborn.axisgrid.FacetGrid at 0x1e7b6599508>"
     },
     "execution_count": 1332,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = predict_blend(validation)\n",
    "sns.displot( np.expm1(submission))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "outputs": [
    {
     "data": {
      "text/plain": "<seaborn.axisgrid.FacetGrid at 0x1e7b6b96ec8>"
     },
     "execution_count": 1333,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(cheat[\"SalePrice\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "outputs": [
    {
     "data": {
      "text/plain": "        Id      SalePrice\n0     1461  135123.684761\n1     1462  165513.556057\n2     1463  193636.760153\n3     1464  196256.648382\n4     1465  182042.473585\n...    ...            ...\n1454  2915   80384.217252\n1455  2916   79210.040866\n1456  2917  162778.084164\n1457  2918  113112.571090\n1458  2919  207984.813590\n\n[1459 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1461</td>\n      <td>135123.684761</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1462</td>\n      <td>165513.556057</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1463</td>\n      <td>193636.760153</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1464</td>\n      <td>196256.648382</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1465</td>\n      <td>182042.473585</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>2915</td>\n      <td>80384.217252</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>2916</td>\n      <td>79210.040866</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>2917</td>\n      <td>162778.084164</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>2918</td>\n      <td>113112.571090</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>2919</td>\n      <td>207984.813590</td>\n    </tr>\n  </tbody>\n</table>\n<p>1459 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 1334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Id': val_ids.to_numpy(), 'SalePrice':  np.expm1(submission)}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.1333949585272273\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"RMSLE: \" + str(rmsle(submission, np.log1p(cheat[\"SalePrice\"]))))\n",
    "\n",
    "plt.plot(np.abs(cheat[\"SalePrice\"].to_numpy() - df[\"SalePrice\"].to_numpy()))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}